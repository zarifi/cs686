{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69mpn6Uvg9ke",
        "outputId": "8b5bf820-b107-4dad-aad3-c1c35377575d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      high\n",
            "1      high\n",
            "2      high\n",
            "3       low\n",
            "4      high\n",
            "       ... \n",
            "995     low\n",
            "996     low\n",
            "997    high\n",
            "998     low\n",
            "999    high\n",
            "Name: class, Length: 1000, dtype: object\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats\n",
        "import copy\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "################# entropoy\n",
        "# Tip: feel free to call scipy.stats.entropy.  Make sure to use log base 2.\n",
        "#\n",
        "# Input:\n",
        "# data_frame -- pandas data frame\n",
        "#\n",
        "# Output:\n",
        "# answer -- float indicating the empirical entropy of tyhe data in data_frame\n",
        "##############################################\n",
        "def entropy(data_frame):\n",
        "\n",
        "\t# default value until this function is filled in\n",
        "\tanswer = 0\n",
        "\treturn answer\n",
        "\n",
        "################# info_gain\n",
        "# Tip: this function should call entropy\n",
        "#\n",
        "# Inputs:\n",
        "# data_frame -- pandas data frame\n",
        "# attribute -- string indicating the attribute for which we wish to compute the information gain\n",
        "# domain -- set of values (strings) that the attribute can take\n",
        "#\n",
        "# Output:\n",
        "# answer -- float indicating the information gain\n",
        "################################################3\n",
        "def info_gain(data_frame, attribute, domain):\n",
        "\n",
        "\t# default value until this function is filled in\n",
        "\tanswer = 0\n",
        "\treturn answer\n",
        "\n",
        "######## Decision_tree class\n",
        "#\n",
        "# This class defines the data structure of the decision tree to be learnt\n",
        "############################\n",
        "class Decision_Tree:\n",
        "\n",
        "\t# constructor\n",
        "\tdef __init__(self,attribute,branches,label):\n",
        "\t\tself.attribute = attribute\n",
        "\t\tself.branches = branches\n",
        "\t\tself.label = label\n",
        "\n",
        "\t# leaf constructor\n",
        "\tdef make_leaf(label):\n",
        "\t\treturn Decision_Tree('class', {}, label)\n",
        "\n",
        "\t# node constructor\n",
        "\tdef make_node(attribute,branches):\n",
        "\t\treturn Decision_Tree(attribute, branches, None)\n",
        "\n",
        "\t# string representation\n",
        "\tdef __repr__(self):\n",
        "\t\treturn self.string_repr(0)\n",
        "\n",
        "\t# decision tree string representation\n",
        "\tdef string_repr(self,indent):\n",
        "\t\tindentation = '\\t'*indent\n",
        "\n",
        "\t\t# leaf string representation\n",
        "\t\tif self.attribute == 'class':\n",
        "\t\t\treturn f'\\n{indentation}class = {self.label}'\n",
        "\n",
        "\t\t# node string representation\n",
        "\t\telse:\n",
        "\t\t\trepresentation = ''\n",
        "\t\t\tfor value in self.branches:\n",
        "\t\t\t\trepresentation += f'\\n{indentation}{self.attribute} = {value}:'\n",
        "\t\t\t\trepresentation += self.branches[value].string_repr(indent+1)\n",
        "\t\t\treturn representation\n",
        "\n",
        "\t# classify a data point\n",
        "\tdef classify(self,data_point):\n",
        "\n",
        "\t\t# leaf\n",
        "\t\tif self.attribute == 'class':\n",
        "\t\t\treturn self.label\n",
        "\n",
        "\t\t# node\n",
        "\t\telse:\n",
        "\t\t\treturn self.branches[data_point[self.attribute]].classify(data_point)\n",
        "\n",
        "############# choose attribute\n",
        "# Tip: this function should call info_gain\n",
        "#\n",
        "# Inputs:\n",
        "# attributes_with_domains -- dictionary with attributes as keys and domains as values\n",
        "# data_frame -- pandas data_frame\n",
        "#\n",
        "# Output:\n",
        "# best_score -- float indicting the information gain score of the best attribute\n",
        "# best_attribute -- string indicating the best attribute\n",
        "#################################\n",
        "def choose_attribute(attributes_with_domains,data_frame):\n",
        "\n",
        "\t# default value until this function is filled in\n",
        "\tbest_score = 0\n",
        "\tbest_attribute = 'MSZoning'\n",
        "\treturn best_score, best_attribute\n",
        "\n",
        "############# train decision tree\n",
        "# Tip: this is a recursive function that should call itself as well as\n",
        "# choose_attribute,  Decision_Tree.make_leaf, Decision_Tree.make_node\n",
        "#\n",
        "# Inputs:\n",
        "# data_frame -- pandas data frame\n",
        "# attributes_with_domains -- dictionary with attributes as keys and domains as values\n",
        "# default_class -- string indicating the class to be assigned when data_frame is empty\n",
        "# threshold -- integer indicating the minimum number of data points in data_frame to allow\n",
        "#              the creation of a new node that splits the data with some attribute\n",
        "#\n",
        "# Output:\n",
        "# decision_tree -- Decision_Tree object\n",
        "########################\n",
        "def train_decision_tree(data_frame,attributes_with_domains,default_class,threshold):\n",
        "\n",
        "\t# default value until this function is filled in\n",
        "\treturn Decision_Tree.make_leaf(default_class)\n",
        "\n",
        "######### eval decision tree\n",
        "# Tip: this function should call decision_tree.classify\n",
        "#\n",
        "# Inputs:\n",
        "# decision tree -- Decision_Tree object\n",
        "# data_frame -- pandas data frame\n",
        "#\n",
        "# Output:\n",
        "# accuracy -- float indicating the accuracy of the decision tree\n",
        "#############\n",
        "def eval_decision_tree(decision_tree, data_frame):\n",
        "\n",
        "\t# default value until this function is filled in\n",
        "\taccuracy = 0\n",
        "\treturn accuracy\n",
        "\n",
        "########### k-fold cross-validation\n",
        "# Tip: this function should call train_decision_tree and eval_decision_tree\n",
        "#\n",
        "# Inputs:\n",
        "# train_data -- pandas data frame\n",
        "# test_data -- pandas data frame\n",
        "# attributes_with_domains -- dictionary with attributes as keys and domains as values\n",
        "# k -- integer indicating the number of folds\n",
        "# threshold_list -- list of thresholds to be evaluated\n",
        "#\n",
        "# Outputs:\n",
        "# best_threshold -- integer indiating the best threshold found by cross validation\n",
        "# test_accuracy -- float indicating the accuracy based on the test set\n",
        "#####################################3\n",
        "def cross_validation(train_data, test_data, attributes_with_domains, k, threshold_list):\n",
        "\n",
        "\t# default value until this function is filled in\n",
        "\tbest_threshold = threshold_list[0]\n",
        "\ttest_accuracy = 0\n",
        "\tdata_x = train_data.drop('class', axis=1)\n",
        "\tdata_y = train_data['class']\n",
        "\t# print(train_data_y)\n",
        "\tkf = KFold(n_split=k)\n",
        "\tfor threshold in threshold_list:\n",
        "\t\tfor train_index, validation_index in kf.split(data_x):\n",
        "\t\t\ttrain_data_x = data_x.iloc[train_index]\n",
        "\t\t\tvalidation_data_x = data_x.iloc[validation_index]\n",
        "\t\t\ttrain_data_y = data_y.iloc[train_index]\n",
        "\t\t\tvalidation_data_y = data_y.iloc[validation_index]\n",
        "\n",
        "\t\t\ttrained_decision_tree = train_decision_tree(train_data_x,attributes_with_domains,'low',threshold)\n",
        "\t\t\tvalidation_accuracy = eval_decision_tree(trained_decision_tree,train_data)\n",
        "\treturn best_threshold, test_accuracy\n",
        "\n",
        "############################ main\n",
        "# You should not need to change the code below\n",
        "#\n",
        "# This code performs the following operations:\n",
        "# 1) Load the data\n",
        "# 2) create a list of attributes\n",
        "# 3) create a dictionary that maps each attribute to its domain of values\n",
        "# 4) split the data into train and test sets\n",
        "# 5) train a decision tree while optimizing the threshold hyperparameter by\n",
        "#    10-fold cross validation\n",
        "#####################################\n",
        "\n",
        "#load data\n",
        "data_frame = pd.read_csv(\"categorical_real_estate.csv\")\n",
        "data_frame = data_frame.fillna('NA')\n",
        "# print(data_frame)\n",
        "\n",
        "# get attributes\n",
        "attributes = list(data_frame.columns)\n",
        "attributes.remove('class')\n",
        "\n",
        "# create dictionary that maps each attribute to its domain of values\n",
        "attributes_with_domains = {}\n",
        "for attr in attributes:\n",
        "\tattributes_with_domains[attr] = set(data_frame[attr])\n",
        "\n",
        "\n",
        "#split data in to train and test\n",
        "train_data = data_frame.iloc[0:1000]\n",
        "test_data = data_frame.iloc[1000:]\n",
        "# print(train_data)\n",
        "# perform 10-fold cross-validation\n",
        "best_threshold, accuracy = cross_validation(train_data, test_data, attributes_with_domains, 10, [10,20,40,80,160])\n",
        "# print(f'Best threshold {best_threshold}: accuracy {accuracy}')\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}